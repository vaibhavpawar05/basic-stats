{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, Masking, Dropout, Bidirectional, GRU\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/vaibhav/MiscProjects/question-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df2_tr = pickle.load(open(base_dir + 'data_df2_tr.pkl', 'rb'))\n",
    "data_df2_ts = pickle.load(open(base_dir + 'data_df2_ts.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>original</th>\n",
       "      <th>row_id</th>\n",
       "      <th>f_Competition</th>\n",
       "      <th>f_Customer</th>\n",
       "      <th>f_Financials</th>\n",
       "      <th>f_Product</th>\n",
       "      <th>f_Strategy</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>What about returns of capital for comparable s...</td>\n",
       "      <td>Financials</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>1098</td>\n",
       "      <td>195</td>\n",
       "      <td>576</td>\n",
       "      <td>32</td>\n",
       "      <td>1005</td>\n",
       "      <td>79</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Can you talk about the HBP EBITDA improvement ...</td>\n",
       "      <td>Financials</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>293</td>\n",
       "      <td>1098</td>\n",
       "      <td>51</td>\n",
       "      <td>279</td>\n",
       "      <td>517</td>\n",
       "      <td>854</td>\n",
       "      <td>459</td>\n",
       "      <td>324</td>\n",
       "      <td>527</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>What is G&amp;A expense?</td>\n",
       "      <td>Financials</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>342</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question    category  original  \\\n",
       "216  What about returns of capital for comparable s...  Financials         1   \n",
       "17   Can you talk about the HBP EBITDA improvement ...  Financials         1   \n",
       "76                                What is G&A expense?  Financials         1   \n",
       "\n",
       "     row_id  f_Competition  f_Customer  f_Financials  f_Product  f_Strategy  \\\n",
       "216     216              0           0             1          0           0   \n",
       "17       17              0           0             1          0           0   \n",
       "76       76              0           0             1          0           0   \n",
       "\n",
       "     0  ...   18    19   20    21   22   23   24    25   26   27  \n",
       "216  0  ...    0     0  324  1098  195  576   32  1005   79  368  \n",
       "17   0  ...  293  1098   51   279  517  854  459   324  527   51  \n",
       "76   0  ...    0     0    0     0    0    0    0   324  342  369  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df2_tr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr = data_df2_tr.values[:, 9:]\n",
    "x_ts = data_df2_ts.values[:, 9:]\n",
    "y_tr = data_df2_tr.values[:, 4:9]\n",
    "y_ts = data_df2_ts.values[:, 4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 28)\n",
      "(125, 28)\n",
      "(401, 5)\n",
      "(125, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.shape)\n",
    "print(x_ts.shape)\n",
    "print(y_tr.shape)\n",
    "print(y_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = pickle.load(open(base_dir + 'embedding_matrix.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_steps = 28\n",
    "onehot_vec_size = 50\n",
    "ncats = 5\n",
    "\n",
    "lstm_size1 = 16\n",
    "\n",
    "input1 = Input(shape=(time_steps,), dtype='int32', name = 'input')\n",
    "\n",
    "# embedding layer to convert into one-hot encoded vector\n",
    "# 0 is mapped to all zeros - this will be ignored when masked\n",
    "# hence, 1st row of embedding matrix is all zero\n",
    "# rest of the matrix is just an identity matrix\n",
    "# this matrix is marked as non-trainable \n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=time_steps,\n",
    "                            trainable=False)\n",
    "\n",
    "embedded_sequences1 = embedding_layer(input1)\n",
    "\n",
    "lstm1 = LSTM(lstm_size1, dropout=0.3, recurrent_dropout=0.3)\n",
    "\n",
    "y1 = Masking(mask_value=0.0)(embedded_sequences1)\n",
    "\n",
    "y1 = lstm1(y1)\n",
    "y = Dropout(0.3)(y1)\n",
    "y = Dense(ncats, activation='softmax')(y)\n",
    "\n",
    "model1 = Model(inputs = input1, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 28, 50)            55500     \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, 28, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                4288      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 59,873\n",
      "Trainable params: 4,373\n",
      "Non-trainable params: 55,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 401 samples, validate on 125 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.6205 - acc: 0.2369 - val_loss: 1.5945 - val_acc: 0.2400\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.6155 - acc: 0.2244 - val_loss: 1.5811 - val_acc: 0.2640\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.6019 - acc: 0.2444 - val_loss: 1.5697 - val_acc: 0.2800\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.5963 - acc: 0.1895 - val_loss: 1.5592 - val_acc: 0.3120\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.6056 - acc: 0.2444 - val_loss: 1.5497 - val_acc: 0.3440\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.5653 - acc: 0.3117 - val_loss: 1.5402 - val_acc: 0.3680\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.5687 - acc: 0.2793 - val_loss: 1.5309 - val_acc: 0.3680\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.5590 - acc: 0.2868 - val_loss: 1.5202 - val_acc: 0.4080\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.5419 - acc: 0.2743 - val_loss: 1.5102 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.5377 - acc: 0.3192 - val_loss: 1.5003 - val_acc: 0.4160\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.5141 - acc: 0.3691 - val_loss: 1.4892 - val_acc: 0.4080\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.5160 - acc: 0.3616 - val_loss: 1.4751 - val_acc: 0.4000\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.5118 - acc: 0.3317 - val_loss: 1.4637 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.4746 - acc: 0.3965 - val_loss: 1.4493 - val_acc: 0.4480\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.4781 - acc: 0.4065 - val_loss: 1.4393 - val_acc: 0.4080\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.4758 - acc: 0.3716 - val_loss: 1.4201 - val_acc: 0.4800\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.4543 - acc: 0.4040 - val_loss: 1.4056 - val_acc: 0.4800\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.4392 - acc: 0.4190 - val_loss: 1.3979 - val_acc: 0.4880\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.4352 - acc: 0.4190 - val_loss: 1.3876 - val_acc: 0.4960\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.4134 - acc: 0.4040 - val_loss: 1.3745 - val_acc: 0.4800\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.3866 - acc: 0.4788 - val_loss: 1.3605 - val_acc: 0.4960\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.3886 - acc: 0.4115 - val_loss: 1.3436 - val_acc: 0.4880\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.3789 - acc: 0.4514 - val_loss: 1.3314 - val_acc: 0.5040\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.3853 - acc: 0.4190 - val_loss: 1.3379 - val_acc: 0.4960\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.3416 - acc: 0.4589 - val_loss: 1.3150 - val_acc: 0.5200\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.3325 - acc: 0.4813 - val_loss: 1.3030 - val_acc: 0.5280\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.3331 - acc: 0.4589 - val_loss: 1.2932 - val_acc: 0.5200\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.3047 - acc: 0.4888 - val_loss: 1.2913 - val_acc: 0.5200\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.2982 - acc: 0.4788 - val_loss: 1.2746 - val_acc: 0.5120\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.2346 - acc: 0.5536 - val_loss: 1.2668 - val_acc: 0.5120\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.2767 - acc: 0.5012 - val_loss: 1.2695 - val_acc: 0.4960\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.2530 - acc: 0.5237 - val_loss: 1.2633 - val_acc: 0.4880\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.2658 - acc: 0.5112 - val_loss: 1.2580 - val_acc: 0.5120\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.2832 - acc: 0.4838 - val_loss: 1.2458 - val_acc: 0.4960\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.2036 - acc: 0.5536 - val_loss: 1.2397 - val_acc: 0.5280\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.2373 - acc: 0.5187 - val_loss: 1.2281 - val_acc: 0.5040\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.1819 - acc: 0.5287 - val_loss: 1.2245 - val_acc: 0.5040\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.2528 - acc: 0.4938 - val_loss: 1.2170 - val_acc: 0.5040\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.1465 - acc: 0.5586 - val_loss: 1.2063 - val_acc: 0.5120\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.1621 - acc: 0.5636 - val_loss: 1.2148 - val_acc: 0.5200\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.1738 - acc: 0.5262 - val_loss: 1.2019 - val_acc: 0.5280\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.1771 - acc: 0.5436 - val_loss: 1.1804 - val_acc: 0.5120\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.1830 - acc: 0.5187 - val_loss: 1.1777 - val_acc: 0.5120\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.1616 - acc: 0.5885 - val_loss: 1.1823 - val_acc: 0.5120\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.1462 - acc: 0.5411 - val_loss: 1.1898 - val_acc: 0.5200\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.1519 - acc: 0.5237 - val_loss: 1.2013 - val_acc: 0.5120\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.1147 - acc: 0.5711 - val_loss: 1.1903 - val_acc: 0.5200\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.0947 - acc: 0.5860 - val_loss: 1.1843 - val_acc: 0.5120\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.1473 - acc: 0.5860 - val_loss: 1.1796 - val_acc: 0.5200\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.0985 - acc: 0.5486 - val_loss: 1.1767 - val_acc: 0.5120\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.1419 - acc: 0.5661 - val_loss: 1.1755 - val_acc: 0.5360\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.0670 - acc: 0.6110 - val_loss: 1.1678 - val_acc: 0.5040\n",
      "Epoch 53/100\n",
      " - 0s - loss: 1.0935 - acc: 0.5636 - val_loss: 1.1739 - val_acc: 0.5200\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.1183 - acc: 0.5736 - val_loss: 1.1854 - val_acc: 0.5200\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.0741 - acc: 0.6010 - val_loss: 1.1835 - val_acc: 0.5200\n",
      "Epoch 56/100\n",
      " - 1s - loss: 1.1095 - acc: 0.5860 - val_loss: 1.1662 - val_acc: 0.5440\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.0621 - acc: 0.6035 - val_loss: 1.1713 - val_acc: 0.5280\n",
      "Epoch 58/100\n",
      " - 0s - loss: 1.0834 - acc: 0.5910 - val_loss: 1.1647 - val_acc: 0.5360\n",
      "Epoch 59/100\n",
      " - 0s - loss: 1.0839 - acc: 0.5586 - val_loss: 1.1584 - val_acc: 0.5520\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.0784 - acc: 0.5860 - val_loss: 1.1720 - val_acc: 0.5280\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.0205 - acc: 0.6334 - val_loss: 1.1638 - val_acc: 0.5600\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.0076 - acc: 0.6135 - val_loss: 1.1561 - val_acc: 0.5600\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.0024 - acc: 0.6060 - val_loss: 1.1553 - val_acc: 0.5280\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.0425 - acc: 0.5761 - val_loss: 1.1527 - val_acc: 0.5520\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.0200 - acc: 0.6409 - val_loss: 1.1460 - val_acc: 0.5680\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.0352 - acc: 0.5885 - val_loss: 1.1334 - val_acc: 0.5760\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.0660 - acc: 0.5736 - val_loss: 1.1359 - val_acc: 0.5680\n",
      "Epoch 68/100\n",
      " - 0s - loss: 1.0105 - acc: 0.5985 - val_loss: 1.1495 - val_acc: 0.5520\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.9779 - acc: 0.6185 - val_loss: 1.1609 - val_acc: 0.5520\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.9861 - acc: 0.6135 - val_loss: 1.1733 - val_acc: 0.5440\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.0211 - acc: 0.6110 - val_loss: 1.1709 - val_acc: 0.5440\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.9794 - acc: 0.6185 - val_loss: 1.1762 - val_acc: 0.5520\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.9739 - acc: 0.6459 - val_loss: 1.1708 - val_acc: 0.5360\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.9711 - acc: 0.6409 - val_loss: 1.1561 - val_acc: 0.5520\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.9725 - acc: 0.6359 - val_loss: 1.1508 - val_acc: 0.5200\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.9719 - acc: 0.6234 - val_loss: 1.1610 - val_acc: 0.4960\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.0089 - acc: 0.6209 - val_loss: 1.1750 - val_acc: 0.5040\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.9839 - acc: 0.6334 - val_loss: 1.1553 - val_acc: 0.5440\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.9583 - acc: 0.6160 - val_loss: 1.1334 - val_acc: 0.5520\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.9527 - acc: 0.6584 - val_loss: 1.1333 - val_acc: 0.5680\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.9807 - acc: 0.6259 - val_loss: 1.1290 - val_acc: 0.5760\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.9724 - acc: 0.6284 - val_loss: 1.1298 - val_acc: 0.5760\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.9473 - acc: 0.6459 - val_loss: 1.1251 - val_acc: 0.5600\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.9392 - acc: 0.6185 - val_loss: 1.1150 - val_acc: 0.5680\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.9928 - acc: 0.6334 - val_loss: 1.1200 - val_acc: 0.5840\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.9459 - acc: 0.6384 - val_loss: 1.1305 - val_acc: 0.5200\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.8907 - acc: 0.6758 - val_loss: 1.1442 - val_acc: 0.5280\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.9096 - acc: 0.6509 - val_loss: 1.1370 - val_acc: 0.5440\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.9278 - acc: 0.6534 - val_loss: 1.1344 - val_acc: 0.5360\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.8989 - acc: 0.6459 - val_loss: 1.1299 - val_acc: 0.5520\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.8774 - acc: 0.6359 - val_loss: 1.1540 - val_acc: 0.5600\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.9173 - acc: 0.6459 - val_loss: 1.1854 - val_acc: 0.5440\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.9374 - acc: 0.6534 - val_loss: 1.1644 - val_acc: 0.5760\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.9491 - acc: 0.6708 - val_loss: 1.1514 - val_acc: 0.5280\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.8845 - acc: 0.6833 - val_loss: 1.1556 - val_acc: 0.5280\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.8911 - acc: 0.6534 - val_loss: 1.1505 - val_acc: 0.5680\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.9231 - acc: 0.6658 - val_loss: 1.1522 - val_acc: 0.5520\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.9187 - acc: 0.6409 - val_loss: 1.1539 - val_acc: 0.5120\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.9471 - acc: 0.6135 - val_loss: 1.1546 - val_acc: 0.5680\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.8677 - acc: 0.6534 - val_loss: 1.1642 - val_acc: 0.5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1293d7ac8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_tr, y_tr,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          validation_data=(x_ts, y_ts),\n",
    "          #callbacks=callbacks,\n",
    "          verbose=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_size1 = 16\n",
    "\n",
    "input1 = Input(shape=(time_steps,), dtype='int32', name = 'input')\n",
    "\n",
    "# embedding layer to convert into one-hot encoded vector\n",
    "# 0 is mapped to all zeros - this will be ignored when masked\n",
    "# hence, 1st row of embedding matrix is all zero\n",
    "# rest of the matrix is just an identity matrix\n",
    "# this matrix is marked as non-trainable \n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=time_steps,\n",
    "                            trainable=False)\n",
    "\n",
    "embedded_sequences1 = embedding_layer(input1)\n",
    "\n",
    "bilstm1 = Bidirectional(LSTM(lstm_size1, dropout=0.3, recurrent_dropout=0.3, return_sequences=False))\n",
    "\n",
    "y1 = Masking(mask_value=0.0)(embedded_sequences1)\n",
    "\n",
    "y1 = bilstm1(y1)\n",
    "y = Dropout(0.3)(y1)\n",
    "y = Dense(ncats, activation='softmax')(y)\n",
    "\n",
    "model2 = Model(inputs = input1, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 401 samples, validate on 125 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.6927 - acc: 0.1920 - val_loss: 1.6085 - val_acc: 0.2480\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.6816 - acc: 0.2195 - val_loss: 1.5870 - val_acc: 0.2320\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.6654 - acc: 0.1920 - val_loss: 1.5767 - val_acc: 0.2800\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.6348 - acc: 0.1970 - val_loss: 1.5683 - val_acc: 0.3360\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.6173 - acc: 0.2444 - val_loss: 1.5600 - val_acc: 0.3440\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.5928 - acc: 0.2718 - val_loss: 1.5519 - val_acc: 0.3600\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.5934 - acc: 0.2594 - val_loss: 1.5444 - val_acc: 0.4080\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.5663 - acc: 0.2968 - val_loss: 1.5368 - val_acc: 0.3680\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.5512 - acc: 0.3242 - val_loss: 1.5261 - val_acc: 0.4480\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.5528 - acc: 0.3267 - val_loss: 1.5153 - val_acc: 0.4560\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.5404 - acc: 0.3192 - val_loss: 1.5052 - val_acc: 0.4320\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.5074 - acc: 0.3466 - val_loss: 1.4937 - val_acc: 0.4400\n",
      "Epoch 13/100\n",
      " - 1s - loss: 1.5376 - acc: 0.3367 - val_loss: 1.4841 - val_acc: 0.4400\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.5082 - acc: 0.3466 - val_loss: 1.4728 - val_acc: 0.4320\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.4862 - acc: 0.3616 - val_loss: 1.4625 - val_acc: 0.4080\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.4456 - acc: 0.4040 - val_loss: 1.4448 - val_acc: 0.4640\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.4551 - acc: 0.3915 - val_loss: 1.4286 - val_acc: 0.4640\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.4482 - acc: 0.4314 - val_loss: 1.4171 - val_acc: 0.4640\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.4291 - acc: 0.4339 - val_loss: 1.3995 - val_acc: 0.4960\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.3794 - acc: 0.4688 - val_loss: 1.3790 - val_acc: 0.4960\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.4029 - acc: 0.4339 - val_loss: 1.3592 - val_acc: 0.5040\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.3845 - acc: 0.4638 - val_loss: 1.3490 - val_acc: 0.4880\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.3692 - acc: 0.4564 - val_loss: 1.3248 - val_acc: 0.5360\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.3486 - acc: 0.4339 - val_loss: 1.3186 - val_acc: 0.5040\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.3138 - acc: 0.5012 - val_loss: 1.3053 - val_acc: 0.5200\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.3034 - acc: 0.4988 - val_loss: 1.2767 - val_acc: 0.5600\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.2863 - acc: 0.5037 - val_loss: 1.2613 - val_acc: 0.5520\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.2490 - acc: 0.5337 - val_loss: 1.2472 - val_acc: 0.5600\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.2471 - acc: 0.5187 - val_loss: 1.2327 - val_acc: 0.5680\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.2436 - acc: 0.5162 - val_loss: 1.2196 - val_acc: 0.5760\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.2311 - acc: 0.5137 - val_loss: 1.2102 - val_acc: 0.5600\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.1750 - acc: 0.5461 - val_loss: 1.1969 - val_acc: 0.5600\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.2241 - acc: 0.5087 - val_loss: 1.1884 - val_acc: 0.5840\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.1712 - acc: 0.5337 - val_loss: 1.1829 - val_acc: 0.5600\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.1476 - acc: 0.5436 - val_loss: 1.1666 - val_acc: 0.5600\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.1482 - acc: 0.5536 - val_loss: 1.1637 - val_acc: 0.5600\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.1379 - acc: 0.5661 - val_loss: 1.1540 - val_acc: 0.5760\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.1260 - acc: 0.5611 - val_loss: 1.1533 - val_acc: 0.5520\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.1468 - acc: 0.5586 - val_loss: 1.1533 - val_acc: 0.5760\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.1049 - acc: 0.5636 - val_loss: 1.1536 - val_acc: 0.5680\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.1050 - acc: 0.5586 - val_loss: 1.1412 - val_acc: 0.5600\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.0955 - acc: 0.5761 - val_loss: 1.1300 - val_acc: 0.5440\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.0940 - acc: 0.5761 - val_loss: 1.1314 - val_acc: 0.5600\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.0779 - acc: 0.5786 - val_loss: 1.1250 - val_acc: 0.5840\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.0449 - acc: 0.6010 - val_loss: 1.1240 - val_acc: 0.5680\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.0811 - acc: 0.5586 - val_loss: 1.1123 - val_acc: 0.5600\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.0503 - acc: 0.6060 - val_loss: 1.1181 - val_acc: 0.5760\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.0565 - acc: 0.5786 - val_loss: 1.1087 - val_acc: 0.5680\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.9912 - acc: 0.6434 - val_loss: 1.1137 - val_acc: 0.5760\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.9947 - acc: 0.6509 - val_loss: 1.1230 - val_acc: 0.5920\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.0479 - acc: 0.5761 - val_loss: 1.1141 - val_acc: 0.5920\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.0352 - acc: 0.6234 - val_loss: 1.0983 - val_acc: 0.5760\n",
      "Epoch 53/100\n",
      " - 0s - loss: 1.0023 - acc: 0.6309 - val_loss: 1.0946 - val_acc: 0.5760\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.9544 - acc: 0.6484 - val_loss: 1.1054 - val_acc: 0.6000\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.0022 - acc: 0.6010 - val_loss: 1.1231 - val_acc: 0.5920\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.9461 - acc: 0.6459 - val_loss: 1.1248 - val_acc: 0.6000\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.0077 - acc: 0.6160 - val_loss: 1.1068 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.9582 - acc: 0.6384 - val_loss: 1.1120 - val_acc: 0.6000\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.9766 - acc: 0.6434 - val_loss: 1.1155 - val_acc: 0.6000\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.9147 - acc: 0.6509 - val_loss: 1.1261 - val_acc: 0.6000\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.9597 - acc: 0.6334 - val_loss: 1.1111 - val_acc: 0.6080\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.9400 - acc: 0.6509 - val_loss: 1.1037 - val_acc: 0.5920\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.9313 - acc: 0.6559 - val_loss: 1.1018 - val_acc: 0.6080\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.9282 - acc: 0.6608 - val_loss: 1.1058 - val_acc: 0.6160\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.9088 - acc: 0.6783 - val_loss: 1.0978 - val_acc: 0.6080\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.9440 - acc: 0.6259 - val_loss: 1.0890 - val_acc: 0.5840\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.9165 - acc: 0.6559 - val_loss: 1.0938 - val_acc: 0.5840\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.8952 - acc: 0.6584 - val_loss: 1.1084 - val_acc: 0.6000\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.8986 - acc: 0.6708 - val_loss: 1.1136 - val_acc: 0.5920\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.8624 - acc: 0.6958 - val_loss: 1.0915 - val_acc: 0.6240\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.8762 - acc: 0.6758 - val_loss: 1.0852 - val_acc: 0.6240\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.8617 - acc: 0.6958 - val_loss: 1.0958 - val_acc: 0.6160\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.8578 - acc: 0.6783 - val_loss: 1.0848 - val_acc: 0.6160\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.8779 - acc: 0.6708 - val_loss: 1.0910 - val_acc: 0.6160\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.8587 - acc: 0.6883 - val_loss: 1.0925 - val_acc: 0.6160\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.8385 - acc: 0.6883 - val_loss: 1.0935 - val_acc: 0.6080\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.8659 - acc: 0.6683 - val_loss: 1.0990 - val_acc: 0.6080\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.8333 - acc: 0.6683 - val_loss: 1.0977 - val_acc: 0.6000\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.8957 - acc: 0.6534 - val_loss: 1.1056 - val_acc: 0.5840\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.8644 - acc: 0.6858 - val_loss: 1.1021 - val_acc: 0.6320\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.8824 - acc: 0.6908 - val_loss: 1.1102 - val_acc: 0.5920\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.8290 - acc: 0.6908 - val_loss: 1.0973 - val_acc: 0.6080\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.8013 - acc: 0.7007 - val_loss: 1.0977 - val_acc: 0.6320\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.8126 - acc: 0.7157 - val_loss: 1.1065 - val_acc: 0.5920\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.8381 - acc: 0.6808 - val_loss: 1.1171 - val_acc: 0.6000\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.7837 - acc: 0.7032 - val_loss: 1.1102 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.7908 - acc: 0.7032 - val_loss: 1.1075 - val_acc: 0.6080\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.7724 - acc: 0.7207 - val_loss: 1.1163 - val_acc: 0.6000\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.8222 - acc: 0.6858 - val_loss: 1.1243 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.7997 - acc: 0.6933 - val_loss: 1.1287 - val_acc: 0.5840\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.8182 - acc: 0.7007 - val_loss: 1.1296 - val_acc: 0.5760\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.7853 - acc: 0.7157 - val_loss: 1.1270 - val_acc: 0.5840\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.6998 - acc: 0.7431 - val_loss: 1.1188 - val_acc: 0.6080\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.7796 - acc: 0.6908 - val_loss: 1.1313 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.7498 - acc: 0.7207 - val_loss: 1.1514 - val_acc: 0.5920\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.7474 - acc: 0.7282 - val_loss: 1.1493 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.7459 - acc: 0.7406 - val_loss: 1.1328 - val_acc: 0.6080\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.7291 - acc: 0.7282 - val_loss: 1.1470 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.7822 - acc: 0.6883 - val_loss: 1.1385 - val_acc: 0.5760\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.7187 - acc: 0.7307 - val_loss: 1.1330 - val_acc: 0.5840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bda2be0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_tr, y_tr,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          validation_data=(x_ts, y_ts),\n",
    "          #callbacks=callbacks,\n",
    "          verbose=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru_size1 = 16\n",
    "\n",
    "input1 = Input(shape=(time_steps,), dtype='int32', name = 'input')\n",
    "\n",
    "# embedding layer to convert into one-hot encoded vector\n",
    "# 0 is mapped to all zeros - this will be ignored when masked\n",
    "# hence, 1st row of embedding matrix is all zero\n",
    "# rest of the matrix is just an identity matrix\n",
    "# this matrix is marked as non-trainable \n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=time_steps,\n",
    "                            trainable=False)\n",
    "\n",
    "embedded_sequences1 = embedding_layer(input1)\n",
    "\n",
    "bigru1 = Bidirectional(GRU(gru_size1, dropout=0.3, recurrent_dropout=0.3, return_sequences=False))\n",
    "\n",
    "y1 = Masking(mask_value=0.0)(embedded_sequences1)\n",
    "\n",
    "y1 = bigru1(y1)\n",
    "y = Dropout(0.3)(y1)\n",
    "y = Dense(ncats, activation='softmax')(y)\n",
    "\n",
    "model3 = Model(inputs = input1, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 401 samples, validate on 125 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.7851 - acc: 0.2294 - val_loss: 1.6772 - val_acc: 0.2240\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.6752 - acc: 0.2120 - val_loss: 1.6195 - val_acc: 0.1840\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.6902 - acc: 0.2070 - val_loss: 1.5972 - val_acc: 0.2240\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.6463 - acc: 0.2594 - val_loss: 1.5798 - val_acc: 0.2640\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.6191 - acc: 0.2544 - val_loss: 1.5650 - val_acc: 0.2880\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.6190 - acc: 0.2594 - val_loss: 1.5504 - val_acc: 0.2720\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.5806 - acc: 0.2718 - val_loss: 1.5374 - val_acc: 0.2800\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.5475 - acc: 0.2768 - val_loss: 1.5228 - val_acc: 0.3040\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.5224 - acc: 0.3491 - val_loss: 1.5099 - val_acc: 0.3280\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.5169 - acc: 0.3566 - val_loss: 1.5010 - val_acc: 0.3200\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.5163 - acc: 0.3267 - val_loss: 1.4866 - val_acc: 0.3680\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.5097 - acc: 0.3292 - val_loss: 1.4739 - val_acc: 0.3840\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.4330 - acc: 0.3990 - val_loss: 1.4619 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.4546 - acc: 0.3566 - val_loss: 1.4500 - val_acc: 0.4080\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.4336 - acc: 0.3865 - val_loss: 1.4370 - val_acc: 0.4320\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.4146 - acc: 0.3791 - val_loss: 1.4270 - val_acc: 0.4320\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.4144 - acc: 0.4165 - val_loss: 1.4171 - val_acc: 0.4320\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.3971 - acc: 0.4065 - val_loss: 1.4059 - val_acc: 0.4480\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.3737 - acc: 0.4339 - val_loss: 1.3958 - val_acc: 0.4640\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.3915 - acc: 0.3990 - val_loss: 1.3849 - val_acc: 0.4640\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.3485 - acc: 0.4489 - val_loss: 1.3749 - val_acc: 0.4560\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.3279 - acc: 0.4564 - val_loss: 1.3623 - val_acc: 0.4640\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.3464 - acc: 0.4339 - val_loss: 1.3505 - val_acc: 0.4640\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.3311 - acc: 0.4539 - val_loss: 1.3403 - val_acc: 0.4560\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1.2954 - acc: 0.4713 - val_loss: 1.3284 - val_acc: 0.4880\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.2797 - acc: 0.4813 - val_loss: 1.3190 - val_acc: 0.4720\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.3210 - acc: 0.4489 - val_loss: 1.3084 - val_acc: 0.4800\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.2823 - acc: 0.4888 - val_loss: 1.2978 - val_acc: 0.5040\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.2275 - acc: 0.5262 - val_loss: 1.2861 - val_acc: 0.5120\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.2238 - acc: 0.5087 - val_loss: 1.2778 - val_acc: 0.5040\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.2870 - acc: 0.4813 - val_loss: 1.2708 - val_acc: 0.5040\n",
      "Epoch 32/100\n",
      " - 0s - loss: 1.2264 - acc: 0.5237 - val_loss: 1.2596 - val_acc: 0.5040\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.1777 - acc: 0.5486 - val_loss: 1.2472 - val_acc: 0.5040\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.1721 - acc: 0.5387 - val_loss: 1.2390 - val_acc: 0.5120\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.1753 - acc: 0.5511 - val_loss: 1.2270 - val_acc: 0.5120\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.1427 - acc: 0.5436 - val_loss: 1.2172 - val_acc: 0.5280\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.1722 - acc: 0.5137 - val_loss: 1.2102 - val_acc: 0.5360\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.1024 - acc: 0.5761 - val_loss: 1.2027 - val_acc: 0.5680\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.1470 - acc: 0.5686 - val_loss: 1.1965 - val_acc: 0.5440\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.0905 - acc: 0.5835 - val_loss: 1.1922 - val_acc: 0.5440\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.1378 - acc: 0.5561 - val_loss: 1.1857 - val_acc: 0.5520\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.0856 - acc: 0.5860 - val_loss: 1.1800 - val_acc: 0.5600\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.0756 - acc: 0.5711 - val_loss: 1.1715 - val_acc: 0.5760\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.0846 - acc: 0.5711 - val_loss: 1.1742 - val_acc: 0.5680\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.0242 - acc: 0.6110 - val_loss: 1.1662 - val_acc: 0.5760\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.0454 - acc: 0.6035 - val_loss: 1.1602 - val_acc: 0.5680\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.0580 - acc: 0.5761 - val_loss: 1.1576 - val_acc: 0.5760\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.0255 - acc: 0.6135 - val_loss: 1.1486 - val_acc: 0.5600\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.0274 - acc: 0.6060 - val_loss: 1.1381 - val_acc: 0.5600\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.0285 - acc: 0.6160 - val_loss: 1.1373 - val_acc: 0.5600\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.0281 - acc: 0.6010 - val_loss: 1.1382 - val_acc: 0.5440\n",
      "Epoch 52/100\n",
      " - 0s - loss: 1.0180 - acc: 0.6359 - val_loss: 1.1330 - val_acc: 0.5520\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.9891 - acc: 0.6185 - val_loss: 1.1281 - val_acc: 0.5520\n",
      "Epoch 54/100\n",
      " - 0s - loss: 1.0350 - acc: 0.6085 - val_loss: 1.1247 - val_acc: 0.5520\n",
      "Epoch 55/100\n",
      " - 0s - loss: 1.0084 - acc: 0.6284 - val_loss: 1.1280 - val_acc: 0.5760\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.9378 - acc: 0.6359 - val_loss: 1.1232 - val_acc: 0.5440\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.9433 - acc: 0.6359 - val_loss: 1.1144 - val_acc: 0.5520\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.9667 - acc: 0.6234 - val_loss: 1.1093 - val_acc: 0.5600\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.9704 - acc: 0.6135 - val_loss: 1.1095 - val_acc: 0.5840\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.9452 - acc: 0.6259 - val_loss: 1.1059 - val_acc: 0.5840\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.9103 - acc: 0.6783 - val_loss: 1.1019 - val_acc: 0.5760\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.9359 - acc: 0.6434 - val_loss: 1.1033 - val_acc: 0.5840\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.9136 - acc: 0.6509 - val_loss: 1.0907 - val_acc: 0.5920\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.9168 - acc: 0.6434 - val_loss: 1.0977 - val_acc: 0.5520\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.8522 - acc: 0.7157 - val_loss: 1.0933 - val_acc: 0.5600\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.9367 - acc: 0.6060 - val_loss: 1.0941 - val_acc: 0.5760\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.9395 - acc: 0.6459 - val_loss: 1.0911 - val_acc: 0.6160\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.8908 - acc: 0.6608 - val_loss: 1.0940 - val_acc: 0.5600\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.9084 - acc: 0.6534 - val_loss: 1.1005 - val_acc: 0.5520\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.8806 - acc: 0.6708 - val_loss: 1.1085 - val_acc: 0.5520\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.9023 - acc: 0.6833 - val_loss: 1.0973 - val_acc: 0.6000\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.9387 - acc: 0.6484 - val_loss: 1.0980 - val_acc: 0.6000\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.8962 - acc: 0.6559 - val_loss: 1.0929 - val_acc: 0.5680\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.8269 - acc: 0.7107 - val_loss: 1.0944 - val_acc: 0.5600\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.9218 - acc: 0.6384 - val_loss: 1.0885 - val_acc: 0.5840\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.8839 - acc: 0.6658 - val_loss: 1.0917 - val_acc: 0.5760\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.8826 - acc: 0.6658 - val_loss: 1.0894 - val_acc: 0.6080\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.8397 - acc: 0.6908 - val_loss: 1.0979 - val_acc: 0.5760\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.8713 - acc: 0.6883 - val_loss: 1.0945 - val_acc: 0.5760\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.8191 - acc: 0.6908 - val_loss: 1.0990 - val_acc: 0.5760\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.8492 - acc: 0.6883 - val_loss: 1.1008 - val_acc: 0.5760\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.8700 - acc: 0.6783 - val_loss: 1.1092 - val_acc: 0.5760\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.8214 - acc: 0.7057 - val_loss: 1.1054 - val_acc: 0.5520\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.8582 - acc: 0.6808 - val_loss: 1.1038 - val_acc: 0.5440\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.8664 - acc: 0.6608 - val_loss: 1.1009 - val_acc: 0.5680\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.8544 - acc: 0.6733 - val_loss: 1.1003 - val_acc: 0.5840\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.8676 - acc: 0.6658 - val_loss: 1.1059 - val_acc: 0.5680\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.8210 - acc: 0.6883 - val_loss: 1.1070 - val_acc: 0.5600\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.8185 - acc: 0.6758 - val_loss: 1.1095 - val_acc: 0.5680\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.7960 - acc: 0.6958 - val_loss: 1.1021 - val_acc: 0.5840\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.7921 - acc: 0.7007 - val_loss: 1.1029 - val_acc: 0.5760\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.7949 - acc: 0.7032 - val_loss: 1.1196 - val_acc: 0.5760\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.7288 - acc: 0.7456 - val_loss: 1.1157 - val_acc: 0.5920\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.7675 - acc: 0.7157 - val_loss: 1.1003 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.7592 - acc: 0.7406 - val_loss: 1.1059 - val_acc: 0.5680\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.7718 - acc: 0.7132 - val_loss: 1.1105 - val_acc: 0.5600\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.7454 - acc: 0.7456 - val_loss: 1.1172 - val_acc: 0.5760\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.8093 - acc: 0.6758 - val_loss: 1.1053 - val_acc: 0.5680\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.7552 - acc: 0.7307 - val_loss: 1.1088 - val_acc: 0.5600\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.7553 - acc: 0.7431 - val_loss: 1.1106 - val_acc: 0.5760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bebf278>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_tr, y_tr,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          validation_data=(x_ts, y_ts),\n",
    "          #callbacks=callbacks,\n",
    "          verbose=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model3.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.560</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.640</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.576</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.582490</td>\n",
       "      <td>0.600527</td>\n",
       "      <td>0.576</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.582490</td>\n",
       "      <td>0.600527</td>\n",
       "      <td>0.576</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision  recall  support\n",
       "0             0.583333   0.608696   0.560     25.0\n",
       "1             0.680851   0.727273   0.640     25.0\n",
       "2             0.666667   0.750000   0.600     25.0\n",
       "3             0.489796   0.500000   0.480     25.0\n",
       "4             0.491803   0.416667   0.600     25.0\n",
       "micro avg     0.576000   0.576000   0.576    125.0\n",
       "macro avg     0.582490   0.600527   0.576    125.0\n",
       "weighted avg  0.582490   0.600527   0.576    125.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(np.argmax(y_ts, axis=1), np.argmax(y_pred, axis=1), \n",
    "             output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix],\n",
    "                  trainable=False)(inp)\n",
    "    x = Bidirectional(LSTM(300, return_sequences=True, dropout=0.25,\n",
    "                           recurrent_dropout=0.25))(x)\n",
    "    x = Attention(maxlen)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru_size1 = 16\n",
    "\n",
    "input1 = Input(shape=(time_steps,), dtype='int32', name = 'input')\n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=time_steps,\n",
    "                            trainable=False)\n",
    "\n",
    "embedded_sequences1 = embedding_layer(input1)\n",
    "\n",
    "bigru1 = Bidirectional(GRU(gru_size1, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "\n",
    "y1 = Masking(mask_value=0.0)(embedded_sequences1)\n",
    "\n",
    "y1 = bigru1(y1)\n",
    "\n",
    "y1 = Attention(time_steps)(y1)\n",
    "\n",
    "y = Dropout(0.3)(y1)\n",
    "y = Dense(ncats, activation='softmax')(y)\n",
    "\n",
    "model4 = Model(inputs = input1, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 401 samples, validate on 125 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.7708 - acc: 0.2195 - val_loss: 1.6188 - val_acc: 0.2400\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.6925 - acc: 0.2095 - val_loss: 1.5918 - val_acc: 0.2640\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.6752 - acc: 0.2269 - val_loss: 1.5776 - val_acc: 0.2560\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.6524 - acc: 0.2369 - val_loss: 1.5656 - val_acc: 0.3120\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.6219 - acc: 0.2319 - val_loss: 1.5528 - val_acc: 0.2960\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.6028 - acc: 0.2519 - val_loss: 1.5411 - val_acc: 0.3200\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.6146 - acc: 0.2319 - val_loss: 1.5281 - val_acc: 0.3440\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.5698 - acc: 0.2693 - val_loss: 1.5181 - val_acc: 0.3520\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.5434 - acc: 0.3142 - val_loss: 1.5046 - val_acc: 0.4160\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.5423 - acc: 0.3017 - val_loss: 1.4902 - val_acc: 0.4000\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.5134 - acc: 0.3516 - val_loss: 1.4760 - val_acc: 0.4160\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.5049 - acc: 0.3217 - val_loss: 1.4596 - val_acc: 0.4480\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.4697 - acc: 0.3915 - val_loss: 1.4442 - val_acc: 0.4480\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.4535 - acc: 0.3840 - val_loss: 1.4281 - val_acc: 0.4560\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.4322 - acc: 0.3940 - val_loss: 1.4103 - val_acc: 0.4480\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.4202 - acc: 0.3915 - val_loss: 1.3947 - val_acc: 0.4560\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.3759 - acc: 0.4613 - val_loss: 1.3779 - val_acc: 0.4640\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.3890 - acc: 0.4564 - val_loss: 1.3604 - val_acc: 0.4800\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.3569 - acc: 0.4564 - val_loss: 1.3406 - val_acc: 0.5040\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.3572 - acc: 0.4439 - val_loss: 1.3264 - val_acc: 0.4960\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.3461 - acc: 0.4738 - val_loss: 1.3110 - val_acc: 0.5120\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.3028 - acc: 0.5062 - val_loss: 1.3013 - val_acc: 0.5120\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.3055 - acc: 0.5062 - val_loss: 1.2810 - val_acc: 0.5600\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.2859 - acc: 0.4988 - val_loss: 1.2662 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1.2853 - acc: 0.4763 - val_loss: 1.2587 - val_acc: 0.5600\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.2338 - acc: 0.5237 - val_loss: 1.2422 - val_acc: 0.5760\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.2588 - acc: 0.5212 - val_loss: 1.2306 - val_acc: 0.5920\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.2436 - acc: 0.5461 - val_loss: 1.2217 - val_acc: 0.5920\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.1916 - acc: 0.5736 - val_loss: 1.2141 - val_acc: 0.5760\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.2181 - acc: 0.5486 - val_loss: 1.2043 - val_acc: 0.5920\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.2035 - acc: 0.5062 - val_loss: 1.2028 - val_acc: 0.5840\n",
      "Epoch 32/100\n",
      " - 0s - loss: 1.1805 - acc: 0.5761 - val_loss: 1.1951 - val_acc: 0.5840\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.1988 - acc: 0.5387 - val_loss: 1.1792 - val_acc: 0.5840\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.1265 - acc: 0.6010 - val_loss: 1.1767 - val_acc: 0.6000\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.1422 - acc: 0.5387 - val_loss: 1.1718 - val_acc: 0.5920\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.1235 - acc: 0.5736 - val_loss: 1.1682 - val_acc: 0.6080\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.1101 - acc: 0.6135 - val_loss: 1.1664 - val_acc: 0.6000\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.1368 - acc: 0.5711 - val_loss: 1.1559 - val_acc: 0.6000\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.1078 - acc: 0.5711 - val_loss: 1.1481 - val_acc: 0.5840\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.0770 - acc: 0.6110 - val_loss: 1.1452 - val_acc: 0.5840\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.1002 - acc: 0.5910 - val_loss: 1.1356 - val_acc: 0.5840\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.1001 - acc: 0.5810 - val_loss: 1.1309 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.0587 - acc: 0.6160 - val_loss: 1.1259 - val_acc: 0.5920\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.0527 - acc: 0.5786 - val_loss: 1.1295 - val_acc: 0.6080\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.0588 - acc: 0.5960 - val_loss: 1.1302 - val_acc: 0.6000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.0558 - acc: 0.6010 - val_loss: 1.1217 - val_acc: 0.6000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.0201 - acc: 0.6110 - val_loss: 1.1195 - val_acc: 0.6080\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.0423 - acc: 0.6284 - val_loss: 1.1192 - val_acc: 0.6160\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.0386 - acc: 0.6209 - val_loss: 1.1215 - val_acc: 0.6080\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.9968 - acc: 0.6284 - val_loss: 1.1225 - val_acc: 0.6320\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.9923 - acc: 0.6384 - val_loss: 1.1095 - val_acc: 0.6080\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.9864 - acc: 0.6160 - val_loss: 1.1149 - val_acc: 0.6080\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.9802 - acc: 0.6209 - val_loss: 1.1112 - val_acc: 0.6160\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.9735 - acc: 0.6534 - val_loss: 1.1123 - val_acc: 0.6000\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.9683 - acc: 0.6434 - val_loss: 1.1128 - val_acc: 0.6160\n",
      "Epoch 56/100\n",
      " - 0s - loss: 1.0134 - acc: 0.6359 - val_loss: 1.1055 - val_acc: 0.6160\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.9515 - acc: 0.6509 - val_loss: 1.1089 - val_acc: 0.6160\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.9820 - acc: 0.6384 - val_loss: 1.0992 - val_acc: 0.6160\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.9817 - acc: 0.6559 - val_loss: 1.0980 - val_acc: 0.6080\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.9554 - acc: 0.6334 - val_loss: 1.1016 - val_acc: 0.5920\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.9054 - acc: 0.6534 - val_loss: 1.1016 - val_acc: 0.6080\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.9198 - acc: 0.6633 - val_loss: 1.1055 - val_acc: 0.5920\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.9550 - acc: 0.6434 - val_loss: 1.1159 - val_acc: 0.6000\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.9372 - acc: 0.6459 - val_loss: 1.1050 - val_acc: 0.6080\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.9150 - acc: 0.6559 - val_loss: 1.1071 - val_acc: 0.6160\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.9434 - acc: 0.6484 - val_loss: 1.1190 - val_acc: 0.6160\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.8820 - acc: 0.6858 - val_loss: 1.1178 - val_acc: 0.6080\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.9468 - acc: 0.6359 - val_loss: 1.1075 - val_acc: 0.6160\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.8962 - acc: 0.6733 - val_loss: 1.1012 - val_acc: 0.6000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.8909 - acc: 0.6733 - val_loss: 1.1041 - val_acc: 0.5920\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.8927 - acc: 0.6658 - val_loss: 1.1125 - val_acc: 0.5920\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.8843 - acc: 0.6833 - val_loss: 1.1025 - val_acc: 0.5920\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.8958 - acc: 0.6683 - val_loss: 1.1064 - val_acc: 0.6000\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.8576 - acc: 0.7082 - val_loss: 1.1019 - val_acc: 0.5920\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.8501 - acc: 0.6908 - val_loss: 1.0911 - val_acc: 0.6160\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.8753 - acc: 0.6783 - val_loss: 1.0956 - val_acc: 0.6240\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.8435 - acc: 0.6783 - val_loss: 1.1005 - val_acc: 0.5920\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.8570 - acc: 0.6858 - val_loss: 1.0947 - val_acc: 0.6240\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.8591 - acc: 0.7132 - val_loss: 1.0966 - val_acc: 0.6240\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.8373 - acc: 0.6908 - val_loss: 1.1009 - val_acc: 0.6080\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.8692 - acc: 0.6708 - val_loss: 1.1055 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.8366 - acc: 0.6958 - val_loss: 1.1017 - val_acc: 0.5920\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.8311 - acc: 0.7057 - val_loss: 1.1046 - val_acc: 0.6000\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.8388 - acc: 0.6633 - val_loss: 1.1054 - val_acc: 0.5840\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.8264 - acc: 0.7107 - val_loss: 1.0988 - val_acc: 0.6080\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.8034 - acc: 0.7057 - val_loss: 1.0969 - val_acc: 0.6080\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.8138 - acc: 0.6883 - val_loss: 1.0865 - val_acc: 0.6000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.8394 - acc: 0.6933 - val_loss: 1.0862 - val_acc: 0.6080\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.8260 - acc: 0.6733 - val_loss: 1.0965 - val_acc: 0.5840\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.8119 - acc: 0.6958 - val_loss: 1.0951 - val_acc: 0.5920\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.7844 - acc: 0.7157 - val_loss: 1.1088 - val_acc: 0.5920\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.8412 - acc: 0.6983 - val_loss: 1.1087 - val_acc: 0.5920\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.7951 - acc: 0.6908 - val_loss: 1.1018 - val_acc: 0.6000\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.7612 - acc: 0.7107 - val_loss: 1.1055 - val_acc: 0.6000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.7969 - acc: 0.7282 - val_loss: 1.1034 - val_acc: 0.5920\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.8073 - acc: 0.6908 - val_loss: 1.1079 - val_acc: 0.5760\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.8113 - acc: 0.6908 - val_loss: 1.1025 - val_acc: 0.6080\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.7635 - acc: 0.7282 - val_loss: 1.1185 - val_acc: 0.5920\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.7677 - acc: 0.7431 - val_loss: 1.1034 - val_acc: 0.6080\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.7509 - acc: 0.7307 - val_loss: 1.1047 - val_acc: 0.6080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130bc6f28>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_tr, y_tr,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          validation_data=(x_ts, y_ts),\n",
    "          #callbacks=callbacks,\n",
    "          verbose=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df2_tr2 = pickle.load(open(base_dir + 'data_df2_tr2.pkl', 'rb'))\n",
    "data_df2_ts2 = pickle.load(open(base_dir + 'data_df2_ts2.pkl', 'rb'))\n",
    "elmo_embeddings_matrix = pickle.load(open(base_dir + 'elmo_embeddings_matrix.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6026, 1024)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_embeddings_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 37)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df2_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr2 = data_df2_tr2.values[:, 37:]\n",
    "x_ts2 = data_df2_ts2.values[:, 37:]\n",
    "y_tr2 = data_df2_tr2.values[:, 4:9]\n",
    "y_ts2 = data_df2_ts2.values[:, 4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 38)\n",
      "(125, 38)\n",
      "(401, 5)\n",
      "(125, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr2.shape)\n",
    "print(x_ts2.shape)\n",
    "print(y_tr2.shape)\n",
    "print(y_ts2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru_size1 = 4\n",
    "time_steps = 38\n",
    "\n",
    "input1 = Input(shape=(time_steps,), dtype='int32', name = 'input')\n",
    "\n",
    "embedding_layer = Embedding(elmo_embeddings_matrix.shape[0],\n",
    "                            elmo_embeddings_matrix.shape[1],\n",
    "                            weights=[elmo_embeddings_matrix],\n",
    "                            input_length=time_steps,\n",
    "                            trainable=False)\n",
    "\n",
    "embedded_sequences1 = embedding_layer(input1)\n",
    "\n",
    "bigru1 = Bidirectional(GRU(gru_size1, dropout=0.4, recurrent_dropout=0.3, return_sequences=True))\n",
    "\n",
    "y1 = Masking(mask_value=0.0)(embedded_sequences1)\n",
    "\n",
    "y1 = bigru1(y1)\n",
    "\n",
    "y1 = Attention(time_steps)(y1)\n",
    "\n",
    "y = Dropout(0.5)(y1)\n",
    "y = Dense(ncats, activation='softmax')(y)\n",
    "\n",
    "model5 = Model(inputs = input1, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 401 samples, validate on 125 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 1.7057 - acc: 0.2344 - val_loss: 1.5664 - val_acc: 0.2800\n",
      "Epoch 2/20\n",
      " - 1s - loss: 1.5983 - acc: 0.2793 - val_loss: 1.5113 - val_acc: 0.3360\n",
      "Epoch 3/20\n",
      " - 1s - loss: 1.5193 - acc: 0.3167 - val_loss: 1.4739 - val_acc: 0.3680\n",
      "Epoch 4/20\n",
      " - 1s - loss: 1.4560 - acc: 0.3940 - val_loss: 1.4457 - val_acc: 0.4000\n",
      "Epoch 5/20\n",
      " - 1s - loss: 1.3713 - acc: 0.4414 - val_loss: 1.3957 - val_acc: 0.4880\n",
      "Epoch 6/20\n",
      " - 1s - loss: 1.3410 - acc: 0.4489 - val_loss: 1.3737 - val_acc: 0.4560\n",
      "Epoch 7/20\n",
      " - 1s - loss: 1.3021 - acc: 0.4988 - val_loss: 1.3238 - val_acc: 0.5120\n",
      "Epoch 8/20\n",
      " - 1s - loss: 1.2791 - acc: 0.4913 - val_loss: 1.2967 - val_acc: 0.5440\n",
      "Epoch 9/20\n",
      " - 1s - loss: 1.1922 - acc: 0.5561 - val_loss: 1.2921 - val_acc: 0.5600\n",
      "Epoch 10/20\n",
      " - 1s - loss: 1.1791 - acc: 0.5810 - val_loss: 1.2646 - val_acc: 0.5520\n",
      "Epoch 11/20\n",
      " - 1s - loss: 1.1234 - acc: 0.5935 - val_loss: 1.2605 - val_acc: 0.4880\n",
      "Epoch 12/20\n",
      " - 1s - loss: 1.0965 - acc: 0.6110 - val_loss: 1.2395 - val_acc: 0.5360\n",
      "Epoch 13/20\n",
      " - 1s - loss: 1.0865 - acc: 0.6110 - val_loss: 1.2142 - val_acc: 0.5840\n",
      "Epoch 14/20\n",
      " - 1s - loss: 1.0373 - acc: 0.6060 - val_loss: 1.2033 - val_acc: 0.5600\n",
      "Epoch 15/20\n",
      " - 1s - loss: 1.0170 - acc: 0.6983 - val_loss: 1.1869 - val_acc: 0.5840\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.9789 - acc: 0.6633 - val_loss: 1.1759 - val_acc: 0.5760\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.9703 - acc: 0.6833 - val_loss: 1.1726 - val_acc: 0.5760\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.9477 - acc: 0.6708 - val_loss: 1.1547 - val_acc: 0.5840\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.9629 - acc: 0.6608 - val_loss: 1.1487 - val_acc: 0.5680\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.8990 - acc: 0.7007 - val_loss: 1.1465 - val_acc: 0.5600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143282898>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(x_tr2, y_tr2,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_data=(x_ts2, y_ts2),\n",
    "          #callbacks=callbacks,\n",
    "          verbose=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(x_ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.76</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.72</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.48</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.60</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.641388</td>\n",
       "      <td>0.648371</td>\n",
       "      <td>0.64</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.641388</td>\n",
       "      <td>0.648371</td>\n",
       "      <td>0.64</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision  recall  support\n",
       "0             0.716981   0.678571    0.76     25.0\n",
       "1             0.711111   0.800000    0.64     25.0\n",
       "2             0.692308   0.666667    0.72     25.0\n",
       "3             0.461538   0.444444    0.48     25.0\n",
       "4             0.625000   0.652174    0.60     25.0\n",
       "micro avg     0.640000   0.640000    0.64    125.0\n",
       "macro avg     0.641388   0.648371    0.64    125.0\n",
       "weighted avg  0.641388   0.648371    0.64    125.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(np.argmax(y_ts2, axis=1), np.argmax(y_pred5, axis=1), \n",
    "             output_dict=True)).transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (for_bert)",
   "language": "python",
   "name": "for_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
