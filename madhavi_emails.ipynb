{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, Masking, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '/home/vaibhavpawar/codes/misc/pred_using_name/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "trdata = np.loadtxt(base_dir + 'madhavi_texts_tr.txt', dtype='int32', delimiter=',')\n",
    "tsdata = np.loadtxt(base_dir + 'madhavi_texts_ts.txt', dtype='int32', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561992, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_window = 25\n",
    "min_chars = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first len_window columns correspond to the historical text window\n",
    "# last column is the next character to be predicted by the model\n",
    "x_tr = trdata[:, 0:len_window]\n",
    "y_tr = trdata[:, len_window]\n",
    "\n",
    "x_vl = tsdata[:, 0:len_window]\n",
    "y_vl = tsdata[:, len_window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_charid = max(np.max(y_vl),np.max(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_charid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create one hot of y\n",
    "y_tr1 = np.zeros((y_tr.shape[0], max_charid))\n",
    "for i in range(0, y_tr.shape[0]):\n",
    "    y_tr1[i, y_tr[i]-1] = 1\n",
    "    \n",
    "y_vl1 = np.zeros((y_vl.shape[0], max_charid))\n",
    "for i in range(0, y_vl.shape[0]):\n",
    "    y_vl1[i, y_vl[i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_steps = len_window\n",
    "onehot_vec_size = max_charid\n",
    "\n",
    "lstm_size1 = 512\n",
    "\n",
    "input1 = Input(shape=(time_steps,), dtype='int32', name = 'input')\n",
    "\n",
    "# embedding layer to convert into one-hot encoded vector\n",
    "# 0 is mapped to all zeros - this will be ignored when masked\n",
    "# hence, 1st row of embedding matrix is all zero\n",
    "# rest of the matrix is just an identity matrix\n",
    "# this matrix is marked as non-trainable \n",
    "\n",
    "embedding_matrix = np.zeros((onehot_vec_size + 1, onehot_vec_size))\n",
    "embedding_matrix[1:,:] = np.identity(onehot_vec_size)\n",
    "\n",
    "embedding_layer = Embedding(onehot_vec_size + 1,\n",
    "                            onehot_vec_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=time_steps,\n",
    "                            trainable=False)\n",
    "\n",
    "embedded_sequences1 = embedding_layer(input1)\n",
    "\n",
    "lstm1 = LSTM(lstm_size1, dropout=0.2, recurrent_dropout=0.2)\n",
    "\n",
    "y1 = Masking(mask_value=0.0)(embedded_sequences1)\n",
    "\n",
    "#sequence_out, y1h, state_c = lstm1(y1)\n",
    "y1 = lstm1(y1)\n",
    "y = Dropout(0.3)(y1)\n",
    "y = Dense(max_charid, activation='softmax')(y)\n",
    "\n",
    "model = Model(inputs = input1, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "file_path = base_dir + 'madhavi_email_char_lstm_model_weights1.hdf5'\n",
    "callbacks = get_callbacks(filepath=file_path, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 561992 samples, validate on 143551 samples\n",
      "Epoch 1/100\n",
      "561992/561992 [==============================] - 3765s 7ms/step - loss: 1.4256 - acc: 0.6053 - val_loss: 1.0089 - val_acc: 0.7088\n",
      "Epoch 2/100\n",
      "561992/561992 [==============================] - 3756s 7ms/step - loss: 1.0178 - acc: 0.7097 - val_loss: 0.8526 - val_acc: 0.7525\n",
      "Epoch 3/100\n",
      "561992/561992 [==============================] - 3766s 7ms/step - loss: 0.9088 - acc: 0.7382 - val_loss: 0.7812 - val_acc: 0.7716\n",
      "Epoch 4/100\n",
      "561992/561992 [==============================] - 3833s 7ms/step - loss: 0.8527 - acc: 0.7522 - val_loss: 0.7409 - val_acc: 0.7821\n",
      "Epoch 5/100\n",
      "561992/561992 [==============================] - 3763s 7ms/step - loss: 0.8163 - acc: 0.7623 - val_loss: 0.7163 - val_acc: 0.7894\n",
      "Epoch 6/100\n",
      "561992/561992 [==============================] - 3739s 7ms/step - loss: 0.7918 - acc: 0.7686 - val_loss: 0.6999 - val_acc: 0.7939\n",
      "Epoch 7/100\n",
      "561992/561992 [==============================] - 3763s 7ms/step - loss: 0.7728 - acc: 0.7732 - val_loss: 0.6875 - val_acc: 0.7975\n",
      "Epoch 8/100\n",
      "561992/561992 [==============================] - 3750s 7ms/step - loss: 0.7580 - acc: 0.7763 - val_loss: 0.6760 - val_acc: 0.7999\n",
      "Epoch 9/100\n",
      "561992/561992 [==============================] - 3756s 7ms/step - loss: 0.7473 - acc: 0.7795 - val_loss: 0.6686 - val_acc: 0.8013\n",
      "Epoch 10/100\n",
      "561992/561992 [==============================] - 3816s 7ms/step - loss: 0.7381 - acc: 0.7815 - val_loss: 0.6648 - val_acc: 0.8034\n",
      "Epoch 11/100\n",
      "561992/561992 [==============================] - 3762s 7ms/step - loss: 0.7296 - acc: 0.7837 - val_loss: 0.6578 - val_acc: 0.8048\n",
      "Epoch 12/100\n",
      "561992/561992 [==============================] - 3775s 7ms/step - loss: 0.7225 - acc: 0.7857 - val_loss: 0.6531 - val_acc: 0.8065\n",
      "Epoch 13/100\n",
      "561992/561992 [==============================] - 3751s 7ms/step - loss: 0.7164 - acc: 0.7872 - val_loss: 0.6491 - val_acc: 0.8070\n",
      "Epoch 14/100\n",
      "561992/561992 [==============================] - 3762s 7ms/step - loss: 0.7103 - acc: 0.7886 - val_loss: 0.6471 - val_acc: 0.8080\n",
      "Epoch 15/100\n",
      "561992/561992 [==============================] - 3753s 7ms/step - loss: 0.7054 - acc: 0.7901 - val_loss: 0.6445 - val_acc: 0.8088\n",
      "Epoch 16/100\n",
      "561992/561992 [==============================] - 3749s 7ms/step - loss: 0.7016 - acc: 0.7905 - val_loss: 0.6419 - val_acc: 0.8095\n",
      "Epoch 17/100\n",
      "561992/561992 [==============================] - 3751s 7ms/step - loss: 0.6966 - acc: 0.7922 - val_loss: 0.6396 - val_acc: 0.8101\n",
      "Epoch 18/100\n",
      "561992/561992 [==============================] - 3742s 7ms/step - loss: 0.6922 - acc: 0.7931 - val_loss: 0.6387 - val_acc: 0.8104\n",
      "Epoch 19/100\n",
      "561992/561992 [==============================] - 3748s 7ms/step - loss: 0.6884 - acc: 0.7943 - val_loss: 0.6353 - val_acc: 0.8113\n",
      "Epoch 20/100\n",
      "561992/561992 [==============================] - 3746s 7ms/step - loss: 0.6859 - acc: 0.7950 - val_loss: 0.6328 - val_acc: 0.8112\n",
      "Epoch 21/100\n",
      "561992/561992 [==============================] - 3750s 7ms/step - loss: 0.6821 - acc: 0.7959 - val_loss: 0.6335 - val_acc: 0.8117\n",
      "Epoch 22/100\n",
      "561992/561992 [==============================] - 3751s 7ms/step - loss: 0.6803 - acc: 0.7960 - val_loss: 0.6292 - val_acc: 0.8121\n",
      "Epoch 23/100\n",
      "561992/561992 [==============================] - 3745s 7ms/step - loss: 0.6772 - acc: 0.7969 - val_loss: 0.6301 - val_acc: 0.8129\n",
      "Epoch 24/100\n",
      "561992/561992 [==============================] - 3746s 7ms/step - loss: 0.6758 - acc: 0.7975 - val_loss: 0.6282 - val_acc: 0.8131\n",
      "Epoch 25/100\n",
      "561992/561992 [==============================] - 3745s 7ms/step - loss: 0.6725 - acc: 0.7982 - val_loss: 0.6271 - val_acc: 0.8137\n",
      "Epoch 26/100\n",
      "561992/561992 [==============================] - 3741s 7ms/step - loss: 0.6686 - acc: 0.7989 - val_loss: 0.6271 - val_acc: 0.8134\n",
      "Epoch 27/100\n",
      "561992/561992 [==============================] - 3747s 7ms/step - loss: 0.6688 - acc: 0.7990 - val_loss: 0.6271 - val_acc: 0.8140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85763019e8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_tr, y_tr1,\n",
    "          batch_size=64,\n",
    "          epochs=100,\n",
    "          validation_data=(x_vl, y_vl1),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {' ': 2, '!': 1, '\"': 4, '#': 3, '%': 5, '&': 7, \"'\": 6, '(': 9, ')': 8,\n",
    " '*': 11, '+': 10, ',': 13, '-': 12, '.': 15, '/': 14, '0': 17, '1': 16, '2': 19,\n",
    " '3': 18, '4': 21, '5': 20, '6': 23, '7': 22, '8': 25, '9': 24, ':': 27, ';': 26,\n",
    " '<': 29, '=': 28, '>': 31, '?': 30, '@': 32, 'E': 68, 'S': 67, 'U': 0, '[': 33, '\\\\': 35,\n",
    " ']': 34, '_': 36, 'a': 37, 'b': 39, 'c': 38, 'd': 41, 'e': 40, 'f': 43, 'g': 42,\n",
    " 'h': 45, 'i': 44, 'j': 47, 'k': 46, 'l': 49, 'm': 48, 'n': 51, 'o': 50, 'p': 53,\n",
    " 'q': 52, 'r': 55, 's': 54, 't': 57, 'u': 56, 'v': 59, 'w': 58, 'x': 61, 'y': 60,\n",
    " 'z': 63, '{': 62, '|': 65, '}': 64, '~': 66}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rev_mapping = {}\n",
    "for key in mapping:\n",
    "    rev_mapping[mapping[key]-1] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_mapping[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why is the code campaign kanishk. thanks & regards, madhavi kaivalya k | +91-9833943305 | senior manager - analytics | loylty rewardz <http://bit.do/lranalytics> what's analytics?\n"
     ]
    }
   ],
   "source": [
    "seed_ = 'why'\n",
    "len_seed_ = len(seed_)\n",
    "randomness = 0.4\n",
    "\n",
    "seed = ''.join(['U' for i in range(0, len_window - len_seed_ -1)]) + 'S' + seed_\n",
    "\n",
    "seed_input = np.zeros((1, len_window), dtype='int32')\n",
    "generated = ''\n",
    "while True:\n",
    "    for i in range(0, len_window):\n",
    "        seed_input[0, i] = mapping[seed[i]]\n",
    "        pred = model.predict(seed_input)\n",
    "        \n",
    "    charid = np.random.choice(max_charid, replace=False, p=pred.reshape((max_charid, )))\n",
    "    if np.random.uniform() <= randomness:\n",
    "        char = rev_mapping[charid]\n",
    "    else:\n",
    "        char = rev_mapping[np.argmax(pred)]\n",
    "        \n",
    "    if char == 'E':\n",
    "        break\n",
    "        \n",
    "    generated = generated + char\n",
    "    \n",
    "    seed = seed[1:] + char\n",
    "    seed_input = np.zeros((1, len_window), dtype='int32')\n",
    "    \n",
    "#print(seed.replace('U', '').replace('S', '') + generated)\n",
    "print(seed_ + generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tflatest]",
   "language": "python",
   "name": "conda-env-tflatest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
