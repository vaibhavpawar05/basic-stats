# -*- coding: utf-8 -*-
"""causality

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nde2CSGOjM1ksS5malIZq8y22Y4CyjL2
"""

import numpy as np
import seaborn as sns
import pandas as pd

def process1(x=None, y=None, n=1):
    if x:
        if y:
            return x*np.ones((n,)), y*np.ones((n,))
        else:
            y = x + 1 + np.sqrt(3)*np.random.normal(size=n)
            return x*np.ones((n,)), y
    else:
        if y:
            x = np.random.normal(size=n)
            return x, y*np.ones((n,))
        else:
            x = np.random.normal(size=n)
            y = x + 1 + np.sqrt(3)*np.random.normal(size=n)
            return x, y

def process2(x=None, y=None, n=1):
    if x:
        if y:
            return x*np.ones((n,)), y*np.ones((n,))
        else:
            y = 1 + 2*np.random.normal(size=n)
            return x*np.ones((n,)), y
    else:
        if y:
            x = (y - 1)/4 + np.sqrt(3)*np.random.normal(size=n)/2
            return x, y*np.ones((n,))
        else:
            y = 1 + 2*np.random.normal(size=n)
            x = (y - 1)/4 + np.sqrt(3)*np.random.normal(size=n)/2
            return x, y

def process3(x=None, y=None, n=1):
    z = np.random.normal(size=n)
    if x:
        if y:
            return x*np.ones((n,)), y*np.ones((n,))
        else:
            y = z + 1 + np.sqrt(3)*np.random.normal(size=n)
            return x*np.ones((n,)), y
    else:
        if y:
            x = z
            return x, y*np.ones((n,))
        else:
            y = z + 1 + np.sqrt(3)*np.random.normal(size=n)
            x = z
            return x, y

data1 = process1(n=1000)
data1a = pd.DataFrame({'x':data1[0], 'y':data1[1]})

g = sns.JointGrid(data=data1a, x="x", y="y")
g.plot(sns.scatterplot, sns.histplot)

data2 = process2(n=1000)
data2a = pd.DataFrame({'x':data2[0], 'y':data2[1]})

g = sns.JointGrid(data=data2a, x="x", y="y")
g.plot(sns.scatterplot, sns.histplot)

data3 = process3(n=1000)
data3a = pd.DataFrame({'x':data3[0], 'y':data3[1]})

g = sns.JointGrid(data=data3a, x="x", y="y")
g.plot(sns.scatterplot, sns.histplot)

data1 = process1(x=3, n=1000)
data1a = pd.DataFrame({'x':data1[0], 'y':data1[1]})

g = sns.JointGrid(data=data1a, x="x", y="y", ylim=(-8,8))
g.plot(sns.scatterplot, sns.histplot)

data2 = process2(x=3, n=1000)
data2a = pd.DataFrame({'x':data2[0], 'y':data2[1]})

g = sns.JointGrid(data=data2a, x="x", y="y", ylim=(-8,8))
g.plot(sns.scatterplot, sns.histplot)

data3 = process3(x=3, n=1000)
data3a = pd.DataFrame({'x':data3[0], 'y':data3[1]})

g = sns.JointGrid(data=data3a, x="x", y="y", ylim=(-8,8))
g.plot(sns.scatterplot, sns.histplot)

data1 = process1(n=10000)
data1a = pd.DataFrame({'x':data1[0], 'y':data1[1]})

data2 = process2(n=10000)
data2a = pd.DataFrame({'x':data2[0], 'y':data2[1]})

data3 = process3(n=10000)
data3a = pd.DataFrame({'x':data3[0], 'y':data3[1]})

print(np.mean(data1a['x']), np.std(data1a['x']), np.mean(data1a['y']), np.std(data1a['y']))
print(np.mean(data2a['x']), np.std(data2a['x']), np.mean(data2a['y']), np.std(data2a['y']))
print(np.mean(data3a['x']), np.std(data3a['x']), np.mean(data3a['y']), np.std(data3a['y']))

# conditional distibution with x = 1

data1a_ = data1a[(data1a['x'] >= 0.95) & (data1a['x'] <= 1.05)]
data2a_ = data2a[(data2a['x'] >= 0.95) & (data2a['x'] <= 1.05)]
data3a_ = data3a[(data3a['x'] >= 0.95) & (data3a['x'] <= 1.05)]

data1a_.shape, data2a_.shape, data3a_.shape

print(np.mean(data1a_['x']), np.std(data1a_['x']), np.mean(data1a_['y']), np.std(data1a_['y']))
print(np.mean(data2a_['x']), np.std(data2a_['x']), np.mean(data2a_['y']), np.std(data2a_['y']))
print(np.mean(data3a_['x']), np.std(data3a_['x']), np.mean(data3a_['y']), np.std(data3a_['y']))

data2 = process2(x=1, n=240)
data2b = pd.DataFrame({'x':data2[0], 'y':data2[1]})

print(np.mean(data2b['x']), np.std(data2b['x']), np.mean(data2b['y']), np.std(data2b['y']))

# good control
# controlling for the confounder
# simpson's paradox

from sklearn.linear_model import LinearRegression

# columns - kidney stone size, treatment
x = np.array([[0, 0],
              [0, 0],
              [0, 1],
              [0, 1],
              [1, 0],
              [1, 0],
              [1, 1],
              [1, 1]])

y = np.array([0, 1, 0, 1, 0, 1, 0, 1])

sample_wt = np.array([150, 50, 180, 180, 50, 200, 4, 36])

reg = LinearRegression()

reg.fit(x, y, sample_weight=sample_wt)

reg.coef_
# this says that treatment 1 is better than 2 by 0.21

